# LinkedIn Posts Extractor con Apify

Sistema de extracci√≥n de posts de LinkedIn usando Apify, integrado con HubSpot para obtener perfiles y crear deals.

## Caracter√≠sticas

- üîç Extracci√≥n de posts de LinkedIn usando Apify Actor
- üîÑ Integraci√≥n con HubSpot (obtener perfiles desde listas y crear deals)
- üíº Creaci√≥n de deals en HubSpot para cada post encontrado
- üìä Rate limiting configurable (m√°ximo de perfiles por d√≠a)
- ‚è∞ Scheduler configurable (ejecuci√≥n autom√°tica peri√≥dica)
- üõ°Ô∏è Detecci√≥n de duplicados
- üìù Logging completo

## Instalaci√≥n

```bash
# Ir a la carpeta backend
cd backend

# Instalar dependencias
npm install
```

## Configuraci√≥n

Crea un archivo `.env` en la carpeta `backend` bas√°ndote en `.env.example`:

```env
# Apify Configuration
APIFY_API_TOKEN=tu_token_de_apify
APIFY_ACTOR_ID=A3cAPGpwBEG8RJwse
APIFY_BATCH_SIZE=10  # N√∫mero de perfiles por lote (recomendado: 10-20)

# HubSpot Configuration
HUBSPOT_TOKEN=tu_token_de_hubspot
HUBSPOT_LIST_ID=5557
# Pipeline y Stage de HubSpot (opcional, si no se configuran se usa el pipeline "Prospecci√≥n" y su primer stage)
HUBSPOT_PIPELINE_ID=811215668
HUBSPOT_DEAL_STAGE_ID=1194313030

# Server Configuration
PORT=3003
NODE_ENV=development

# Rate Limiting
MAX_PROFILES_PER_DAY=50

# Scheduling Configuration (in minutes)
# How often to run the scraping process
# Examples: 60 = every hour, 1440 = once per day, 30 = every 30 minutes
SCRAPE_INTERVAL_MINUTES=60

# Apify Actor Input Configuration
MAX_POSTS=5
INCLUDE_QUOTE_POSTS=true
INCLUDE_REPOSTS=false
SCRAPE_REACTIONS=false
MAX_REACTIONS=5
SCRAPE_COMMENTS=false
MAX_COMMENTS=5

# Logging
LOG_LEVEL=INFO
```

### Variables de Entorno

#### Apify
- `APIFY_API_TOKEN`: Token de API de Apify (requerido)
- `APIFY_ACTOR_ID`: ID del Actor de Apify (por defecto: `A3cAPGpwBEG8RJwse`)
- `APIFY_BATCH_SIZE`: N√∫mero de perfiles por lote para evitar timeouts (por defecto: `10`, recomendado: `10-20`)

#### HubSpot
- `HUBSPOT_TOKEN`: Token de API de HubSpot (requerido)
- `HUBSPOT_LIST_ID`: ID de la lista de HubSpot (por defecto: `5557`)

#### HubSpot (para crear deals)
- `HUBSPOT_PIPELINE_ID`: ID num√©rico del pipeline (opcional, por defecto: `811215668` - Pipeline "Prospecci√≥n")
- `HUBSPOT_DEAL_STAGE_ID`: ID num√©rico del stage (opcional, si no se especifica usa el primer stage del pipeline configurado)
  
  **Ejemplo de configuraci√≥n:**
  ```env
  HUBSPOT_PIPELINE_ID=811215668
  HUBSPOT_DEAL_STAGE_ID=1194313030  # "Hip√≥tesis OK" - primer stage del pipeline Prospecci√≥n
  ```

#### Rate Limiting
- `MAX_PROFILES_PER_DAY`: M√°ximo n√∫mero de perfiles a procesar por d√≠a (por defecto: `50`)

#### Scheduling
- `SCRAPE_INTERVAL_MINUTES`: Intervalo en minutos entre ejecuciones autom√°ticas (por defecto: `60`)
  - `0` o no configurado: Deshabilita el scheduler
  - Ejemplos: `30` = cada 30 minutos, `60` = cada hora, `1440` = una vez al d√≠a

#### Apify Actor Input
- `MAX_POSTS`: M√°ximo n√∫mero de posts a extraer por perfil (por defecto: `5`)
- `INCLUDE_QUOTE_POSTS`: Incluir quote posts (por defecto: `true`)
- `INCLUDE_REPOSTS`: Incluir reposts (por defecto: `false`)
- `SCRAPE_REACTIONS`: Extraer reacciones (por defecto: `false`)
- `MAX_REACTIONS`: M√°ximo n√∫mero de reacciones (por defecto: `5`)
- `SCRAPE_COMMENTS`: Extraer comentarios (por defecto: `false`)
- `MAX_COMMENTS`: M√°ximo n√∫mero de comentarios (por defecto: `5`)

## Uso

### Opci√≥n 1: Servidor con Scheduler Autom√°tico

```bash
# Ir a la carpeta backend
cd backend

# Iniciar servidor (el scheduler se iniciar√° autom√°ticamente si est√° configurado)
npm start
```

El servidor iniciar√° y ejecutar√° el scraping autom√°ticamente seg√∫n el intervalo configurado en `SCRAPE_INTERVAL_MINUTES`.

### Opci√≥n 2: API REST

```bash
# Ir a la carpeta backend
cd backend

# Iniciar servidor
npm start

# Ejecutar scraping manualmente
curl -X POST http://localhost:3003/api/scraper/run-now

# Obtener estad√≠sticas
curl http://localhost:3003/api/scraper/stats

# Extraer posts de perfiles espec√≠ficos
curl -X POST http://localhost:3003/api/scraper/extract-posts \
  -H "Content-Type: application/json" \
  -d '{
    "profileLinks": [
      "https://www.linkedin.com/in/satyanadella/",
      "https://www.linkedin.com/in/billgates/"
    ]
  }'

# Extraer posts desde HubSpot
curl -X POST http://localhost:3003/api/scraper/extract-posts \
  -H "Content-Type: application/json" \
  -d '{
    "useHubSpot": true
  }'
```

### Opci√≥n 3: Obtener informaci√≥n de un deal espec√≠fico

```bash
# Ir a la carpeta backend
cd backend

# Obtener informaci√≥n de un deal por su ID
npm run get-deal-info 1234567890

# O directamente con node
node scripts/get-deal-info.js 1234567890
```

Este comando mostrar√° **ABSOLUTAMENTE TODAS** las propiedades disponibles del deal, organizadas en secciones:

- **üîπ INFORMACI√ìN DEL OBJETO**: ID, estado, fechas del objeto
- **‚≠ê PROPIEDADES PRINCIPALES**: dealname, amount, pipeline, stage, etc.
- **üìÖ FECHAS IMPORTANTES**: createdate, hs_lastmodifieddate, closedate
- **üìä ESTADOS DEL DEAL**: hs_is_closed, hs_is_closed_won, probabilidad
- **üìà ANALYTICS**: Fuente y datos de analytics
- **üîó PROPIEDADES DE LINKEDIN**: URLs de posts
- **üîç TODAS LAS PROPIEDADES DISPONIBLES**: Lista completa alfab√©tica (con contador total)
- **üíª JSON COMPLETO**: Para desarrolladores

**üöÄ Caracter√≠sticas avanzadas:**
- ‚úÖ **Obtenci√≥n autom√°tica de todas las propiedades**: No necesitas especificar qu√© propiedades consultar
- ‚úÖ **Incluye TODAS las propiedades**: Est√°ndar y personalizadas con valores no vac√≠os
- ‚úÖ **Optimizaci√≥n de rendimiento**: Evita URLs demasiado largas consultando eficientemente
- ‚úÖ **Muestra el total de propiedades encontradas**
- ‚úÖ **Formateo inteligente**: Fechas, booleanos y valores vac√≠os se muestran correctamente
- ‚úÖ **Sin l√≠mites**: Obtiene todas las propiedades disponibles en tiempo real

## API Endpoints

### GET /health
Health check del servidor.

### POST /api/scraper/extract-posts
Extraer posts de perfiles de LinkedIn.

**Request (con profileLinks):**
```json
{
  "profileLinks": [
    "https://www.linkedin.com/in/profile1",
    "https://www.linkedin.com/in/profile2"
  ]
}
```

**Request (desde HubSpot):**
```json
{
  "useHubSpot": true
}
```

**Response:**
```json
{
  "success": true,
  "results": [
    {
      "profileUrl": "https://www.linkedin.com/in/profile1",
      "profileName": "John Doe",
      "postUrl": "https://www.linkedin.com/feed/update/...",
      "success": true,
      "hubspotDealId": "52688453993",
      "duplicate": false
    }
  ],
  "summary": {
    "total": 2,
    "successful": 1,
    "failed": 0,
    "duplicates": 0,
    "profilesProcessed": 2
  },
  "stats": {
    "date": "2024-01-15",
    "count": 2,
    "limit": 50,
    "remaining": 48
  }
}
```

### POST /api/scraper/run-now
Ejecutar scraping manualmente (usa perfiles de HubSpot).

### GET /api/scraper/stats
Obtener estad√≠sticas de rate limit y estado del scheduler.

**Response:**
```json
{
  "success": true,
  "rateLimit": {
    "date": "2024-01-15",
    "count": 10,
    "limit": 50,
    "remaining": 40
  },
  "scheduler": {
    "isRunning": false,
    "isScheduled": true,
    "intervalMinutes": 60
  }
}
```

## Estructura del Proyecto

```
linkedin-posts-apify/
‚îî‚îÄ‚îÄ backend/
    ‚îú‚îÄ‚îÄ controllers/
    ‚îÇ   ‚îî‚îÄ‚îÄ scraperController.js
    ‚îú‚îÄ‚îÄ routes/
    ‚îÇ   ‚îî‚îÄ‚îÄ scraperRoutes.js
    ‚îú‚îÄ‚îÄ services/
    ‚îÇ   ‚îú‚îÄ‚îÄ apifyService.js
    ‚îÇ   ‚îú‚îÄ‚îÄ hubspotService.js (obtener perfiles y crear deals)
    ‚îÇ   ‚îú‚îÄ‚îÄ loggerService.js
    ‚îÇ   ‚îú‚îÄ‚îÄ rateLimitService.js
    ‚îÇ   ‚îî‚îÄ‚îÄ schedulerService.js
    ‚îú‚îÄ‚îÄ scripts/
    ‚îÇ   ‚îú‚îÄ‚îÄ scrape.js
    ‚îÇ   ‚îî‚îÄ‚îÄ test-structure.js
    ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îú‚îÄ‚îÄ logs/
    ‚îÇ   ‚îî‚îÄ‚îÄ rate-limit.json
    ‚îú‚îÄ‚îÄ .env.example
    ‚îú‚îÄ‚îÄ package.json
    ‚îú‚îÄ‚îÄ server.js
    ‚îî‚îÄ‚îÄ README.md
```

## Flujo de Trabajo

1. **Obtener perfiles desde HubSpot**: El sistema obtiene perfiles de LinkedIn desde una lista de HubSpot
2. **Verificar rate limit**: Se verifica si se puede procesar m√°s perfiles hoy
3. **Dividir en lotes**: Los perfiles se dividen en lotes seg√∫n `APIFY_BATCH_SIZE` (por defecto 10)
4. **Extraer posts con Apify**: Se usa el Actor de Apify para extraer posts de los perfiles (por lotes)
5. **Crear deals en HubSpot**: Para cada post extra√≠do, se crea un deal en HubSpot (si no es duplicado)
6. **Actualizar rate limit**: Se incrementa el contador de perfiles procesados

### ¬øPor qu√© dividir en lotes?

Cuando se procesan muchos perfiles (ej: 100+), hacer una sola llamada a Apify puede causar:
- Timeouts de conexi√≥n (`ECONNRESET`)
- Respuestas demasiado grandes
- Fallos en la extracci√≥n

Al dividir en lotes de 10-20 perfiles:
- ‚úÖ Conexiones m√°s estables
- ‚úÖ Mejor manejo de errores (si falla un lote, los dem√°s contin√∫an)
- ‚úÖ Progreso visible en tiempo real

## Rate Limiting

El sistema implementa un rate limiting diario para evitar exceder l√≠mites de API:

- El contador se resetea cada d√≠a a medianoche
- Se puede configurar el m√°ximo de perfiles por d√≠a con `MAX_PROFILES_PER_DAY`
- El sistema verifica autom√°ticamente antes de procesar perfiles

## Scheduler

El scheduler ejecuta el proceso de scraping autom√°ticamente seg√∫n el intervalo configurado:

- Configura `SCRAPE_INTERVAL_MINUTES` para establecer el intervalo
- El scheduler usa `node-cron` para ejecutar tareas programadas
- Si una ejecuci√≥n est√° en curso, la siguiente se saltar√°

## Detecci√≥n de Duplicados

El sistema verifica duplicados antes de crear deals en HubSpot:

- Busca deals existentes en HubSpot que contengan el URL del post en la descripci√≥n
- Compara URLs de posts
- Si encuentra un duplicado, lo marca pero no crea una nueva tarea

## Logging

Los logs se guardan en `data/logs/` con un archivo por d√≠a:

- Formato: `YYYY-MM-DD.log`
- Niveles: DEBUG, INFO, WARN, ERROR, SUCCESS, CRITICAL
- Configurable con `LOG_LEVEL`

## Troubleshooting

### Error: "APIFY_API_TOKEN no est√° configurado"
- Verifica que tengas un archivo `.env` con `APIFY_API_TOKEN` configurado
- Obt√©n tu token desde https://console.apify.com/account/integrations

### Error: "HUBSPOT_TOKEN no est√° configurado"
- Verifica que tengas `HUBSPOT_TOKEN` en tu `.env`
- Obt√©n tu token desde https://app.hubspot.com/settings/integrations/api

### Error: "HUBSPOT_TOKEN no est√° configurado"
- Verifica que tengas `HUBSPOT_TOKEN` en tu `.env`
- Obt√©n tu token desde HubSpot Settings ‚Üí Integrations ‚Üí Private Apps

### L√≠mite diario alcanzado
- El sistema respeta el l√≠mite configurado en `MAX_PROFILES_PER_DAY`
- Espera hasta el siguiente d√≠a o aumenta el l√≠mite en `.env`

### Scheduler no ejecuta
- Verifica que `SCRAPE_INTERVAL_MINUTES` est√© configurado y sea mayor que 0
- Revisa los logs para ver si hay errores

## Tecnolog√≠as

- **Node.js**: Runtime de JavaScript
- **Express**: Framework web
- **Apify Client**: Cliente para Apify Actors
- **Axios**: Cliente HTTP
- **node-cron**: Scheduler de tareas
- **dotenv**: Gesti√≥n de variables de entorno

## Licencia

ISC

# linkedin-scrapper-posts-apify
# linkedin-scrapper-posts-apify
# linkedin-scrapper-posts-apify
# linkedin-scrapper-posts-apify
# linkedin-posts-scrapper
